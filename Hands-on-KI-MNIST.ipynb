{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on KI mit PyTorch: MNIST (20 Minuten)\n",
    "\n",
    "In diesem Notebook wirst du ein einfaches neuronales Netz auf dem MNIST-Datensatz trainieren. \n",
    "Wichtige Teile fehlen absichtlich – du wirst sie selbst implementieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST-Datensatz laden\n",
    "Wir laden Trainings- und Testdaten.\n",
    "\n",
    "Es ist wichtig die seperate Trainings und Testdaten zu definieren um festzustellen ob ein overfitting stattfindet.\n",
    "Overfitting bezeichnet ein auswendig Lernen der exakten Testdaten im Gegensatz zum Lernen von Mustern.\n",
    "Der Testdatensatz überprüft daher, ob das Modell mit Daten umgehen kann welche es noch nie gesehen hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 1-2 Beispiele plotten\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "plt.figure(figsize=(5,2))\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "    plt.title(f'Label: {example_targets[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neuronales Netz definieren\n",
    "\n",
    "✍️ **Aufgabe:** Implementiere ein einfaches fully connected Netzwerk.\n",
    "- Wähle die Anzahl der Hidden Layer (1 oder 2)\n",
    "- Wähle die Layer-Größen (z.B. 2, 16, 64, 128)\n",
    "- Wähle die Aktivierungsfunktion (ReLU, Sigmoid, Tanh)\n",
    "\n",
    "**Hinweis / Beispiel:**\\\n",
    "In der init Funktion musst du alle Layer und Aktivierungsfunktionen die du nutzen willst definieren.\\\n",
    "Achte darauf, dass du bei mehreren Layern (z.B. Linear) die Dimensionen für input und output entsprechend wählst.\\\n",
    "! Die letzte Layer sollte auf 10 Outputs reduzieren ! \n",
    "```python\n",
    "self.fc1 = nn.Linear(28*28, 2)  # Layergröße ändern nach Wahl\n",
    "self.fc2 = nn.Linear(2, 32) # Layer mit 128 inputs und 32 Outputs\n",
    "self.act = nn.ReLU()  # Aktivierung wählen\n",
    "```\n",
    "\n",
    "Die forward Funktion reicht die Daten weiter zwischen den Layers\n",
    "```python\n",
    "data_after_layer_one = self.fc1(x)\n",
    "data_after_activation_function = self.act(data_after_layer_one)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # TODO: Definiere deine Layer hier\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implementiere forward pass\n",
    "        pass\n",
    "\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training vorbereiten\n",
    "\n",
    "✍️ **Aufgabe:** Wähle Loss-Funktion und Optimizer\n",
    "- Loss: CrossEntropyLoss, MSELoss (Mean-Squared-Error), L1Loss (Mean-Absolute-Error), ... [more](https://neptune.ai/blog/pytorch-loss-functions)\n",
    "- Optimizer: SGD oder Adam\n",
    "\n",
    "**Hinweis / Beispiel:**\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Loss & Optimizer definieren\n",
    "criterion = None  # setze Loss-Funktion\n",
    "optimizer = None  # setze Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trainingsloop\n",
    "\n",
    "✍️ **Aufgabe:** Implementiere den Trainingsloop für z.B. 3 Epochen\n",
    "\n",
    "**Hinweis / Beispiel:**\n",
    "```python\n",
    "for epoch in range(3):\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()                       # zurücksetzen aller Gradienten\n",
    "        output = model(data.view(data.size(0), -1)) # Bilder werden als Vektoren in das Modell gegeben\n",
    "        loss = criterion(output, target)            # Loss/Fehler des Models wird berechnet\n",
    "        loss.backward()                             \n",
    "        # berechnet Gradienten für alle Gewichte/Parameter in Layern\n",
    "        # quasi wie stark der Parameter geändert werden muss damit eher das passende Ergebnis erreicht wird \n",
    "        optimizer.step()                            # Anpassen der Gewichte abhängig von Gradient und learning rate\n",
    "\n",
    "```\n",
    "\n",
    "oft ist es interessant den loss über die Zeit aufzuzeichnen. Um das zu erreichen kannst du die Loss Werte aufzeichnen\n",
    "\n",
    "```python\n",
    "loss_array = []\n",
    "\n",
    "*training_loop*\n",
    "    loss_array.append(loss.item())\n",
    "\n",
    "plt.plot(loss_array)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Trainingsloop einfügen\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Berechne Accuracy auf Testdaten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data.view(data.size(0), -1))\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target).sum().item()\n",
    "        total += target.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ergebnisse visualisieren\n",
    "Zeige einige Testbilder mit Vorhersagen des Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964fe365",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "output = model(example_data.view(example_data.size(0), -1))\n",
    "preds = output.argmax(dim=1)\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(8):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "    plt.title(f'True: {example_targets[i]} Pred: {preds[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a25162",
   "metadata": {},
   "source": [
    "Außerdem schauen wir uns einmal die falsch klassifizierten Zahlen an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eceb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_misclassified_to_show = 5\n",
    "misclassified_found = 1\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data.view(data.size(0), -1))\n",
    "        pred = output.argmax(dim=1)\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            if pred[i] != target[i]:\n",
    "                print(f\"True Label: {target[i].item()}\")\n",
    "                print(f\"Predicted Label: {pred[i].item()}\")\n",
    "                print(f\"Model Outputs (logits): {output[i].numpy()}\")\n",
    "\n",
    "                plt.figure(figsize=(3,3))\n",
    "                plt.imshow(data[i][0], cmap='gray')\n",
    "                plt.title(f'True: {target[i].item()} Pred: {pred[i].item()}')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                misclassified_found +=1\n",
    "                if misclassified_found > number_of_misclassified_to_show:\n",
    "                  break\n",
    "        if misclassified_found>number_of_misclassified_to_show:\n",
    "            break\n",
    "\n",
    "if not misclassified_found:\n",
    "    print(\"No misclassified examples found in the first batch (or no misclassifications at all).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df4a19",
   "metadata": {},
   "source": [
    "<!-- # 7. Spielereien\n",
    "Teste auf einem trainierten Modell ob es deine Zahlen erkennt: [[https://interactive-digit-classifier.onrender.com/](https://interactive-digit-classifier.onrender.com/)]\n",
    "\n",
    "Wie reagiert es auf Buchstaben oder andere Symbole? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb443a",
   "metadata": {},
   "source": [
    "# 7. Spielereien\n",
    "Teste deine eigene Handschrift auf einem trainierten Modell: [interactive-digit-classifier](https://interactive-digit-classifier.onrender.com/) [cnn-playground](https://cnn-playground.live/mnist)\n",
    "\n",
    "Wie reagiert das Modell auf andere Symbole?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
